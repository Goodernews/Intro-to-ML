{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "First steps of ML",
      "provenance": [],
      "collapsed_sections": [
        "f6GG_STGOAaN",
        "Mvk9muh76qVS",
        "pEFiFtEUAubY",
        "DrcgSzyrGh5f",
        "Qf7QZeBPdYlD"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo1hYk_6MAL8",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\n",
        "#@markdown # Introduction to ML (WIP)\n",
        "\n",
        "#@markdown \n",
        "#@markdown By: Taylor Bowen Blair\n",
        "#@markdown \n",
        "#@markdown [Run in Google Colab](https://colab.research.google.com/drive/1OAYlqDtRwhQZkfFtrAmnOBMVmvf7eBXl)\n",
        "#@markdown \n",
        "#@markdown #Prerequisites\n",
        "#@markdown \n",
        "\n",
        "#@markdown *   Basic Python\n",
        "#@markdown *   Knowledge of lists in python\n",
        "#@markdown *  Slope at a point (derivative)\n",
        "\n",
        "#@markdown ##Changing to Python 3:\n",
        "#@markdown The code below is written with functions that only exists in Python 3.\n",
        "#@markdown \n",
        "#@markdown Edit -> Notebook Settings -> Runtime Type -> Python 3\n",
        "#@markdown \n",
        "#@markdown ##Running with GPU:\n",
        "\n",
        "#@markdown Running tensorflow on a GPU is significantly faster, to test how much faster test using [this](https://colab.research.google.com/notebooks/gpu.ipynb).\n",
        "#@markdown \n",
        "#@markdown Edit -> Notebook Settings -> Hardware Accelrator -> GPU\n",
        "#@markdown \n",
        "\n",
        "#@markdown ##Import libraries and Intialize Functions\n",
        "#@markdown The libraries that are used in this \n",
        "\n",
        "#@markdown * **Pandas**\n",
        "#@markdown   * *This is used for tables*\n",
        "#@markdown * **Tensorflow**\n",
        "#@markdown   * *This is the most widely used machine learning library*\n",
        "\n",
        "#@markdown   * **Keras**\n",
        "#@markdown     * *This is an add-on to tensorflow. It simplifies tensorflow makes it more readable.*\n",
        "\n",
        "#@markdown * **Numpy**\n",
        "#@markdown   * *This is a library that helps with math*\n",
        "\n",
        "#@markdown * **Matplotlib** \n",
        "#@markdown   * *This is the most widely used machine learning library*\n",
        "#@markdown * **Seaborn** \n",
        "#@markdown   * *This is used to make a correlation matrix*\n",
        "#@markdown * **ipywidgets** \n",
        "#@markdown   * *This library allows you to interact*\n",
        "\n",
        "\n",
        "#@markdown *Run this cell to import the libraries*\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import optimizers\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from __future__ import print_function\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import ipywidgets as widgets\n",
        "\n",
        "'''\n",
        "Below are functions that are used frequently.\n",
        "DON'T change them\n",
        "'''\n",
        "\n",
        "def root_mean_squared_error(y_true, y_pred): #keras doesn't have a RMSE function, so this is needed\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
        "\n",
        "def load_data(dataset, selected_features, target): #loads the data into the desired forms\n",
        "  x = dataset[selected_features].as_matrix()\n",
        "  y = dataset[target].tolist()\n",
        "  return x,y\n",
        "\n",
        "def model_stats(model, features, targets): #outpus the stats on the model\n",
        "  x, y = load_data(test_set, features, targets)\n",
        "  y = np.array(y)\n",
        "  predictions = model.predict_on_batch(x)\n",
        "  flattened_predict = np.array([val for sublist in predictions for val in sublist])\n",
        "  diffrence = np.absolute(y-flattened_predict)\n",
        "  print(\"Stats on Test Data\")\n",
        "  print(\"Max error: %.2f\" % np.max(diffrence), \"thousand dollars\")\n",
        "  print(\"Min error: %.2f\" % np.min(diffrence), \"thousand dollars\")\n",
        "  print(\"Average error: %.2f\" % np.mean(diffrence), \"thousand dollars\")\n",
        "  print(\"RMSE on test data: %.2f\" % (np.sqrt(np.mean(np.square(flattened_predict-y)))))\n",
        "  \n",
        "def linear_model_graph(history): #graphs the loss over steps\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.title('Model Loss')\n",
        "  plt.ylabel('Root Mean Squared Error')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.show()\n",
        "  \n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSF4V3c0LmUf",
        "colab_type": "text"
      },
      "source": [
        "#1-1. The Basic Terminology of Machine Learning\n",
        "\n",
        "There is lots of unique words that are used when talking about ML, here is some of the most commonly used words. Refer back to this list if you can not find a word\n",
        "\n",
        "---\n",
        "\n",
        "##Tensorflow\n",
        "Tensorflow is a library that is used to create machine learning models.  \n",
        "\n",
        "##Loss\n",
        "Loss is what models reduce, it measures the difference between predicted and actual sets of data.\n",
        "\n",
        "##Weights\n",
        "\n",
        "Weights are the variables in the machine learning equation. Think of them as the **M** in y=mx+b. \n",
        "\n",
        "##MSE\n",
        "![alt text](https://cdn-media-1.freecodecamp.org/images/hmZydSW9YegiMVPWq2JBpOpai3CejzQpGkNG)\n",
        "\n",
        "*Credit: Free code camp*\n",
        "\n",
        "Mean squared error is a simple way to measure loss. It takes the mean residual of the predicted and actual value. \n",
        "\n",
        "##RMSE\n",
        "![alt text](https://i.stack.imgur.com/eG03B.png)\n",
        "\n",
        "*Credit: Stack Exchange*\n",
        "\n",
        "\n",
        "RMSE or Root-mean-square-error is similar to Mean Squared Error. The only difference is the square root is taken after the fact. This is often more useful for when loss is a large number, or when data has a larger standard deviation. \n",
        "\n",
        "##Overfitting\n",
        "![alt text](https://upload.wikimedia.org/wikipedia/commons/6/68/Overfitted_Data.png)\n",
        "\n",
        "*Credit: \"Overfitting\" Wikipedia*\n",
        "\n",
        "Overfitting is one of the most frequent problems in Machine Learning. Overfitting occurs when the model becomes overly complex to reduce loss and comes up with a solution that does not work generally.\n",
        "\n",
        "##Train and Test dataset\n",
        "To check for overfitting Machine learning engineers use train and test datasets. Train datasets are used during the training of a model, and the training dataset is set aside to check the result. \n",
        "\n",
        "![alt text](https://upload.wikimedia.org/wikipedia/commons/thumb/0/0e/Traintest.svg/2880px-Traintest.svg.png)\n",
        "*Credit: \"Training, validation, and test sets\" Wikipedia*\n",
        "\n",
        "\n",
        "\n",
        "If there a significant diffrence in loss between the train and test dataset, the model has likely overfit on the training data.\n",
        "\n",
        "\n",
        "##Stochiastic Gradient Descent\n",
        "![alt text](https://camo.githubusercontent.com/a5ef1165eb365959a8817498bf8acb16c0d88d33/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f313630302f302a7242514937754268424b45384b542d582e706e67)\n",
        "*Credit: Oleksii Trekhleb via Github*\n",
        "\n",
        "Stochiastic gradient descent (SGD for short), is the main way that a model reduces loss, it adjusts the variables by going in the direction of the steepest slope\n",
        "\n",
        "---\n",
        "\n",
        "Machine learning models work by reducing loss in a function, essentially finding the minima of a function. \n",
        "\n",
        "You may be wondering \"*why don't we take the derivative of the function and find where it equals zero?*\" In a way, we are doing that. The only issue is that..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOE4LlcCLOru",
        "colab_type": "text"
      },
      "source": [
        "#1-2 How do Basic Machine Learning Models Learn\n",
        "\n",
        "![alt text](https://www.3d-relief.com/images/product_images/info_images/36_0.jpg)\n",
        "\n",
        "*Credits: 3D-Relief*\n",
        "\n",
        "Imagine a helicopter drops you off at a random place in a mountain range and tells you that you may only leave once you find the lowest point. You do know your current altitude at any given location.\n",
        "\n",
        "**However**, you are not given you a map, directions. As an added catch, difficult, you are blindfolded. \n",
        "\n",
        "You can be reset at another random point any time you ask, but it is not the same place every time. \n",
        "\n",
        "***How would you find the lowest point?***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJe9osXaN2IM",
        "colab_type": "text"
      },
      "source": [
        "*Your answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6GG_STGOAaN",
        "colab_type": "text"
      },
      "source": [
        "##How does a computer do it (*solution*)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX7b1XUOOMbo",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://www.sciencemag.org/sites/default/files/styles/inline__699w__no_aspect/public/ma_0504_NID_alchemy_WEB.jpg?itok=YufMqkHl)\n",
        "\n",
        "*Credits: Science Magizine\n",
        "\n",
        "This is the basic problem behind machine learning, tuning variables to reduce loss. \n",
        "\n",
        "Think about the equation `y=mx+b` that is being fitted to a set of data points. Now lets imagine that the loss/residuals are the alititude of the mountain, and the latitude and longitude are the `m` and `b`. \n",
        "\n",
        "Because it is far to complex (and infinite) to calculate every point, the computer picks a metaphorical point on the mountain and goes towards the direction with the steepest downhill slope.  \n",
        "\n",
        "\n",
        "The only issue is, what if you arrive at a local minimum or gully rather than the global maximum? This is a frequent incident for machine learning models, they often wind up stuck in local minimums. Often times that may be low enough. Going back to our helicopter metaphor, the helicopter pilot can always reset you and drop you off at another part of the mountain which perhaps leads to a better solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwEoSGvoHeRZ",
        "colab_type": "text"
      },
      "source": [
        "#2-1 Creating a Linear Model\n",
        "Linear models are the simplest form of machine learning models. Think of them as being a y=ax+b, z=ax+by+c or higher dimension linear equation. They can take multiple variables, and typically output a number. We will use an example dataset for this lesson"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-68YTPm_8_j2",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown #Boston Housing Data\n",
        "#@markdown Tensorflow Keras includes a number of prepared datasets, one of the intro datasets is boston housing data . The goal is to predict the cost of a house given certain features.\n",
        "from keras.datasets import boston_housing\n",
        "(train_data, train_labels), (test_data, test_labels) = boston_housing.load_data()\n",
        "\n",
        "print(\"The data is: \", test_data[0])\n",
        "print (\"The cost is : \", train_labels[0])\n",
        "print(\"There are \", len(train_labels), \" train data points and \", len(test_labels), \" test data points.\")\n",
        "\n",
        "#@markdown *Run this to load the data.*\n",
        "\n",
        "#@markdown This cell will also print the first line of the data table without labels."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LgMsmUvAAhE",
        "colab_type": "text"
      },
      "source": [
        "The data above makes no sense, without labels. Below are the labels for each column.\n",
        "\n",
        "\n",
        "***\n",
        "> The dataset contains 13 different features:\n",
        "\n",
        "> 1. Per capita crime rate. ```CRIM```\n",
        "2. The proportion of residential land zoned for lots over 25,000 square feet. `ZN`\n",
        "3. The proportion of non-retail business acres per town. `INDUS`\n",
        "4. Charles River dummy variable (= 1 if tract bounds river; 0 otherwise). `CHAS`\n",
        "5. Nitric oxides concentration (parts per 10 million). `NOX`\n",
        "6. The average number of rooms per dwelling. `RM`\n",
        "7. The proportion of owner-occupied units built before 1940. `AGE`\n",
        "8. Weighted distances to five Boston employment centers. `DIS`\n",
        "9. Index of accessibility to radial highways. `RAD`\n",
        "10. Full-value property-tax rate per $10,000. `TAX`\n",
        "11. Pupil-teacher ratio by town. `PTRATIO`\n",
        "12. 1000 * (Bk - 0.63) ** 2 where Bk is the proportion of Black people by town. `B`\n",
        "13. Percentage lower status of the population. `LSTAT`\n",
        "14. Cost for housing in thousands of dollars. `COST`\n",
        "***\n",
        "*Credits: Tensorflow.org*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x6EcY_dALg9",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown With that information you can create a pandas table for the Boston housing data, which is used to train the model.\n",
        "\n",
        "#@markdown *Run this to create the pandas table.*\n",
        "\n",
        "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
        "                'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
        "\n",
        "train_set = pd.DataFrame(train_data, columns=column_names) \n",
        "train_set[\"COST\"] = train_labels\n",
        "\n",
        "test_set = pd.DataFrame(test_data, columns=column_names) \n",
        "test_set[\"COST\"] = test_labels\n",
        "\n",
        "print(\"Train Dataset\")\n",
        "train_set.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlnFt4b4jgQ6",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown *Run this to see statistics on the dataset.*\n",
        "train_set.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNrDCLmOLOFi",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown ---\n",
        "#@markdown \n",
        "#@markdown #Basic Hyperamaters\n",
        "#@markdown \n",
        "#@markdown ##Steps\n",
        "#@markdown Steps are how many times a model trains on the dataset\n",
        "#@markdown ##Learning rate\n",
        "#@markdown If you look at the image that shows the ball going down the parabola you may notice the arrows, \n",
        "\n",
        "#@markdown ##Fetaures\n",
        "\n",
        "#@markdown What the model uses to make a prediction. Features are typically numbers or vectors\n",
        "\n",
        "#@markdown ##Target\n",
        "#@markdown What the model is trying to predict. This could be a boolean, number, word, vector or more!\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown \n",
        "#@markdown **Goal:** Less then 7 RMSE on test data.\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown *Run this to initialize the functions*\n",
        "\n",
        "\n",
        "\n",
        "def create_simple_linear_model(learning_rate, num_data):\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(keras.layers.Dense(1, input_dim=num_data, kernel_initializer='normal', activation='linear'))\n",
        "  model.add(keras.layers.Dense(1, kernel_initializer='normal'))\n",
        "  sgd = optimizers.SGD(lr=learning_rate)\n",
        "  model.compile(loss=root_mean_squared_error, optimizer='sgd')\n",
        "  return model\n",
        "\n",
        "def run_simple_linear_model(learning_rate, steps, targets, features):\n",
        "  model = create_simple_linear_model(learning_rate, len(features))\n",
        "  x_d, y_d = load_data(train_set, features, targets)\n",
        "  history = model.fit(x=x_d, y=y_d, epochs=10, steps_per_epoch = int(steps/10))\n",
        "  linear_model_graph(history)\n",
        "  model_stats(model, features, targets)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYHjkmxRMe8Y",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\n",
        "#@markdown ***If you get nan (not a number) or inf for loss: Decrease steps, loss, or the amount of features.***\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Target**, name of column, only one\n",
        "selected_target = \"COST\" #@param \n",
        "\n",
        "#@markdown **Featres**, names of columns as strings, seperated by comma, fewer is better\n",
        "selected_features = [..., ...] #@param\n",
        "\n",
        "#@markdown **Learning rate**, float less then one\n",
        "learning_rate = 0 #@param {type:\"slider\", min:0, max:0.5, step:0.01}\n",
        "\n",
        "#@markdown **Steps**, integer greater then 10\n",
        "steps = 10 #@param {type:\"slider\", min:10, max:2000, step:1}\n",
        "\n",
        "first_model = run_simple_linear_model(learning_rate, # learning rate, float less then one\n",
        "                                      steps, #steps\n",
        "                                      selected_target, #What the machine is trying to predict\n",
        "                                      selected_features, #The input\n",
        "                                      ) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mvk9muh76qVS",
        "colab_type": "text"
      },
      "source": [
        "#### Possible Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zCvpN6I6u1B",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "This is one possible solution, not the only solution\n",
        "\"\"\"\n",
        "#@markdown **Target**, name of column, only one\n",
        "selected_target = \"COST\" #@param \n",
        "\n",
        "#@markdown **Featres**, names of columns, seperated by comma, fewer is better\n",
        "selected_features = [\"RM\", \"RAD\"] #@param\n",
        "\n",
        "#@markdown **Learning rate**, float less then one\n",
        "learning_rate = 0.07 #@param {type:\"slider\", min:0, max:0.5, step:0.01}\n",
        "\n",
        "#@markdown **Steps**, integer greater then 10\n",
        "steps = 535 #@param {type:\"slider\", min:10, max:5000, step:1}\n",
        "\n",
        "first_model = run_simple_linear_model(learning_rate, # learning rate, float less then one\n",
        "                                      steps, #steps\n",
        "                                      selected_target, #What the machine is trying to predict\n",
        "                                      selected_features, #The input\n",
        "                                      ) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "332sU0yYdQW1",
        "colab_type": "text"
      },
      "source": [
        "##Interact with your model \n",
        "\n",
        "Try using your model to predict several values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ML_Spsrd0Bq",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "model = first_model #@param {type:\"raw\"}\n",
        "\n",
        "#@markdown You will need to copy and paste the features from above\n",
        "interact_features = [...] #@param {type:\"raw\"}\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Try using the sliders to interact with your model. If you did not use a feature, it will not factor into the output.\n",
        "\n",
        "CRIM = 0#@param {type:\"slider\", min:0, max:90, step:0.5}\n",
        "\n",
        "ZN = 0#@param {type:\"slider\", min:0, max:100, step:0.5}\n",
        "\n",
        "INDUS = 0#@param {type:\"slider\", min:0, max:30, step:0.1}\n",
        "\n",
        "CHAS = 0#@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "NOX = 0#@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "RM = 0#@param {type:\"slider\", min:0, max:10, step:0.05}\n",
        "\n",
        "AGE = 0#@param {type:\"slider\", min:0, max:100, step:0.5}\n",
        "\n",
        "DIS = 0#@param {type:\"slider\", min:0, max:11, step:0.05}\n",
        "\n",
        "RAD = 1 #@param {type:\"slider\", min:1, max:25, step:0.25}\n",
        "\n",
        "TAX = 185#@param {type:\"slider\", min:185, max:280, step:0.5}\n",
        "\n",
        "PTRATIO = 12#@param {type:\"slider\", min:12, max:18, step:0.025}\n",
        "\n",
        "B = 0#@param {type:\"slider\", min:0, max:400, step:1}\n",
        "\n",
        "LSTAT = 6#@param {type:\"slider\", min:6, max:38, step:0.5}\n",
        "\n",
        "theoretical_values =  [CRIM, ZN, INDUS, CHAS, NOX, RM, AGE, DIS, RAD, TAX, PTRATIO, B, LSTAT]\n",
        "st= set(interact_features)\n",
        "\n",
        "column_names\n",
        "\n",
        "index_post = [i for i, e in enumerate(column_names) if e in st]\n",
        "index_post = np.array(index_post)\n",
        "\n",
        "features_to_input = np.array([theoretical_values[i] for i in index_post]).reshape(1,len(interact_features))\n",
        "\n",
        "\n",
        "\n",
        "print(\"Cost of house is: $\", str(model.predict(features_to_input)[0][0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aLjL04JQvDI",
        "colab_type": "text"
      },
      "source": [
        "# 2-2. Improving Accuracy\n",
        "Now that you have created your model first model try to improve it. There are two problems you may have encountered in your model are overfitting and underfitting . There are some ways to fix these issues lets improve the accuracy through feature selection\n",
        "***\n",
        "\n",
        "##Feature selection\n",
        "Feature selection is picking only the relevant data to be used in the model. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GmE0-jv7FQt",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Correlation Matrix\n",
        "\n",
        "#@markdown *Run this*\n",
        "\n",
        "#@markdown This is a block of code that creates a correlation matrix. A correlation matrix displays how correlated two points of data are. The more positivly correlated two points of data are, the darker the red. The more negativley correlated two points of data are, the darker the blue. If two points are uncorrelated they are white.\n",
        "\n",
        "f, ax = plt.subplots(figsize=(10, 8))\n",
        "corr = train_set.corr()\n",
        "plt.title(\"Correlation Matrix\")\n",
        "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
        "            square=True, ax=ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq2hNo8PqiY2",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown Guess which are the most correlated then check which are the most correlated, then run this to check. \n",
        "\n",
        "#@markdown *Run this AFTER you do the above.*\n",
        "\n",
        "corr.reindex(corr.COST.abs().sort_values(inplace=False, ascending=False).index)[\"COST\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1obVTtAulPoJ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21qsVoUkbjP_",
        "colab_type": "text"
      },
      "source": [
        "#2-3 Tune your Linear Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIVx-EHQlQyY",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown Now that you know what features are more correlated, update your hyperparameters. \n",
        "\n",
        "#@markdown **Goal**: Less then 6 RSME on test data\n",
        "\n",
        "#@markdown *Run this code cell to intialize the function.*\n",
        "\n",
        "def create_advanced_linear_model(learning_rate, num_data):\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(keras.layers.Dense(1, input_dim=num_data, kernel_initializer='normal', activation='linear'))\n",
        "  model.add(keras.layers.Dense(1, kernel_initializer='normal'))\n",
        "  sgd = optimizers.SGD(lr=learning_rate)\n",
        "  model.compile(loss=root_mean_squared_error, optimizer='sgd')\n",
        "  return model\n",
        "\n",
        "def run_advanced_linear_model(learning_rate, steps, targets, features):\n",
        "  model = create_advanced_linear_model(learning_rate, len(features))\n",
        "  x, y = load_data(train_set, features, targets)\n",
        "  history = model.fit(x, y, epochs=10, steps_per_epoch=round(steps/10))\n",
        "  linear_model_graph(history)\n",
        "  model_stats(model, features, targets)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqg8C2u6oI3_",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "#@markdown ***If you get nan (not a number) or inf for loss: Decrease steps, loss, or the amount of features.***\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Target**, name of column, only one\n",
        "selected_target = \"COST\" #@param \n",
        "\n",
        "#@markdown **Featres**, names of columns as strings, seperated by comma, fewer is better\n",
        "selected_features = [..., ...] #@param\n",
        "\n",
        "#@markdown **Learning rate**, float less then one\n",
        "learning_rate = 0 #@param {type:\"slider\", min:0, max:0.5, step:0.01}\n",
        "\n",
        "#@markdown **Steps**, integer greater then 10\n",
        "steps = 10 #@param {type:\"slider\", min:10, max:2000, step:1}\n",
        "\n",
        "selected_target = \"COST\"\n",
        "selected_features = [..., ....] #names of targets, seperated by comma\n",
        "second_model = run_advanced_linear_model(learning_rate, #learning rate\n",
        "                                         steps, #steps,  how many times the computer trains on the model\n",
        "                                         selected_target, #What the machine is trying to predict\n",
        "                                         selected_features, #The input\n",
        "                                         ) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEFiFtEUAubY",
        "colab_type": "text"
      },
      "source": [
        "##Possible Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wqv0wGeA57F",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\n",
        "#@markdown **Target**, name of column, only one\n",
        "selected_target = \"COST\" #@param \n",
        "\n",
        "#@markdown **Featres**, names of columns as strings, seperated by comma, fewer is better\n",
        "selected_features = [\"LSTAT\", \"RM\"] #@param\n",
        "\n",
        "#@markdown **Learning rate**, float less then one\n",
        "learning_rate = 0.04 #@param {type:\"slider\", min:0, max:0.5, step:0.01}\n",
        "\n",
        "#@markdown **Steps**, integer greater then 10\n",
        "steps = 1287 #@param {type:\"slider\", min:10, max:2000, step:1}\n",
        "\n",
        "second_model = run_advanced_linear_model(learning_rate, #learning rate\n",
        "                                         steps, #steps,  how many times the computer trains on the model\n",
        "                                         selected_target, #What the machine is trying to predict\n",
        "                                         selected_features, #The input\n",
        "                                         ) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2esPSaH0Nuwh",
        "colab_type": "text"
      },
      "source": [
        "#3-1 Neural Net Models\n",
        "\n",
        "Nueral nets are the is the next level in machine learning. In addition to being multi dimensional, they are also non-linear. This means that they no are not restrained to y=mx+b\n",
        "\n",
        "---\n",
        "\n",
        "##Activation Function\n",
        "\n",
        "![alt text](https://miro.medium.com/max/1192/1*4ZEDRpFuCIpUjNgjDdT2Lg.png)\n",
        "*Credits: Pawan Jain from Medium*\n",
        "\n",
        "An activation function is a function that is used to transform the model to be non-linear. \n",
        "\n",
        "##Neurons and Layers\n",
        "![alt text](https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Colored_neural_network.svg/1920px-Colored_neural_network.svg.png)\n",
        "*Credits: Wikipedia Contributers*\n",
        "\n",
        "Neurons are the special sauce and namesake of Neural nets. They take a series of inputs (known as vectors) and transform it using activation functions. They often feed into one another, groupingss of them are reffered to as layers.\n",
        "\n",
        "---\n",
        "\n",
        "##Notes\n",
        " - Learning rate is no longer a tunable hyparamater. This is because nueral nets are much more complex, so the learning rate is now adjusted by the computer. If you are interested in learning more, [here](https://en.wikipedia.org/wiki/Stochastic_gradient_descent#AdaGrad) is a link to a wikipedia page that explains AdaGrad (adaptive gradient algorithm) which is used to adjust the learning rate automatically.\n",
        " - RMSE has been replaced by MSE as the loss function.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Goal**: Create a nueral net that has an RSME less than 5.5 RMSE on the test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ezp2rav8M1i3",
        "colab_type": "text"
      },
      "source": [
        "#3-2 Creating a Basic Neural Net model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVRHJVo8QrQG",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown *Run this to intialize the functions for the Neural Net*\n",
        "def create_simple_neural_net_model(layers, num_data):\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(keras.layers.Dense(layers[0], input_dim=num_data, kernel_initializer='normal', activation='relu'))\n",
        "  for x in range (1,len(layers)):\n",
        "    model.add(keras.layers.Dense(layers[x], kernel_initializer='normal', activation='relu')) \n",
        "  model.add(keras.layers.Dense(1, kernel_initializer='normal'))\n",
        "  model.compile(loss=\"mse\", optimizer='adagrad')\n",
        "  return model\n",
        "\n",
        "def simple_neural_graph(history):\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.title('Model Loss')\n",
        "  plt.ylabel('Mean Squared Error')\n",
        "  plt.xlabel('Epoch')\n",
        "\n",
        "def run_simple_neural_net_model(steps, targets, features, layers):\n",
        "  model = create_simple_neural_net_model(layers, len(features))\n",
        "  x, y = load_data(train_set, features, targets)\n",
        "  history = model.fit(x, y, epochs=10, steps_per_epoch=int(steps/10))\n",
        "  model_stats(model, features, targets)\n",
        "  simple_neural_graph(history)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nNyI9E7P94x",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown **Target**, name of column, only one\n",
        "selected_target = \"COST\" #@param \n",
        "\n",
        "#@markdown **Featres**, names of columns as strings, seperated by comma, fewer is better\n",
        "selected_features = [..., ...] #@param\n",
        "\n",
        "#@markdown **Layers**, number of neurons as integers, seperated by comma. The more layers, the longer it takes to train.\n",
        "model_layers = [..., ...] #@param\n",
        "\n",
        "#@markdown **Steps**, integer greater then 10\n",
        "steps = 10 #@param {type:\"slider\", min:10, max:15000, step:1} \n",
        "\n",
        "\n",
        "first_neural_net = run_simple_neural_net_model(steps, #steps\n",
        "                                               selected_target, #features\n",
        "                                               selected_features, #targets\n",
        "                                               model_layers #layers, integers seperated by commas\n",
        "                                              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrcgSzyrGh5f",
        "colab_type": "text"
      },
      "source": [
        "##Possible Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbKXcJolGiVW",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown **Target**, name of column, only one\n",
        "selected_target = \"COST\" #@param \n",
        "\n",
        "#@markdown **Featres**, names of columns as strings, seperated by comma, fewer is better\n",
        "selected_features = [\"LSTAT\", \"RM\", \"PTRATIO\", \"INDUS\"] #@param\n",
        "\n",
        "#@markdown **Layers**, number of neurons as integers, seperated by comma. The more layers, the longer it takes to train.\n",
        "model_layers = [300, 100, 75, 50, 25] #@param\n",
        "\n",
        "#@markdown **Steps**, integer greater then 10\n",
        "steps = 10000 #@param {type:\"slider\", min:10, max:15000, step:1} \n",
        "\n",
        "\n",
        "first_neural_net = run_simple_neural_net_model(steps, #steps\n",
        "                                               selected_target, #features\n",
        "                                               selected_features, #targets\n",
        "                                               model_layers #layers, integers seperated by commas\n",
        "                                              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D8RANdEIPVz",
        "colab_type": "text"
      },
      "source": [
        "# 3-3 Improving Neural Net Models\n",
        "\n",
        "Unlike linear models, there are an infinite amount of solutions to neural nets, which could lead to overfitting. A simple way to prevent this is with validation data.\n",
        "\n",
        "---\n",
        "\n",
        "##Validation Dataset\n",
        "Validation dataset is an extension to the train and test datasets. Instead of only assessing the accuracy of the model once training is completed, the model can check at the end of every epoch to ensure that it is not overfitting and make adjustments based on that.\n",
        "\n",
        "---\n",
        "##Goal\n",
        "Less than 5 RMSE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKDo1qtTXKGB",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown *Run this to intialize the functions for the Neural Net*\n",
        "def create_better_neural_net_model(layers, num_data):\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(keras.layers.Dense(layers[0], input_dim=num_data, kernel_initializer='normal', activation='relu'))\n",
        "  for x in range (1,len(layers)):\n",
        "    model.add(keras.layers.Dense(layers[x], kernel_initializer='normal', activation='relu')) \n",
        "  model.add(keras.layers.Dense(1, kernel_initializer='normal'))\n",
        "  model.compile(loss=\"mse\", optimizer='adagrad')\n",
        "  return model\n",
        "\n",
        "def simple_neural_graph(history):\n",
        "  plt.plot(np.sqrt(history.history['loss']))\n",
        "  plt.title('Model Loss')\n",
        "  plt.ylabel('Mean Squared Error')\n",
        "  plt.xlabel('Epoch')\n",
        "\n",
        "def run_better_neural_net_model(steps, targets, features, layers, val):\n",
        "  model = create_better_neural_net_model(layers, len(features))\n",
        "  x, y = load_data(train_set, features, targets)\n",
        "  history = model.fit(x, y, epochs=10, validation_split=val, steps_per_epoch=int(steps/10), validation_steps=32)\n",
        "  model_stats(model, features, targets)\n",
        "  simple_neural_graph(history)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmT7Wp9Te9Q3",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\n",
        "#@markdown **Target**, name of column, only one\n",
        "selected_target = \"COST\" #@param \n",
        "\n",
        "#@markdown **Featres**, names of columns as strings, seperated by comma, fewer is better\n",
        "selected_features = [...,...] #@param\n",
        "\n",
        "#@markdown **Layers**, number of neurons as integers, seperated by comma. The more layers, the longer it takes to train.\n",
        "model_layers = [...,...] #@param\n",
        "\n",
        "#@markdown **Percent validation**, percent as a float between zero and one\n",
        "percent_val = 0 #@param {type:\"slider\", min:0, max:1, step:0.01} \n",
        "\n",
        "#@markdown **Steps**, integer greater than ten\n",
        "steps = 10 #@param {type:\"slider\", min:10, max:30000, step:5} \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "first_neural_net = run_better_neural_net_model(20000, #steps\n",
        "                                               selected_target, #features\n",
        "                                               selected_features, #targets\n",
        "                                               model_layers, #layers\n",
        "                                               percent_val #percent validation data, expressed as a decimal\n",
        "                                              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf7QZeBPdYlD",
        "colab_type": "text"
      },
      "source": [
        "##Possible Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pf-aoNggawF1",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\n",
        "#@markdown **Target**, name of column, only one\n",
        "selected_target = \"COST\" #@param \n",
        "\n",
        "#@markdown **Featres**, names of columns as strings, seperated by comma, fewer is better\n",
        "selected_features = [\"LSTAT\", \"RM\", \"TAX\", \"PTRATIO\", \"CRIM\", \"INDUS\", \"ZN\"] #@param\n",
        "\n",
        "#@markdown **Layers**, number of neurons as integers, seperated by comma. The more layers, the longer it takes to train.\n",
        "model_layers = [512, 256, 128, 64] #@param\n",
        "\n",
        "#@markdown **Percent validation**, percent as a float between zero and one\n",
        "percent_val = 0.32 #@param {type:\"slider\", min:0, max:1, step:0.01} \n",
        "\n",
        "#@markdown **Steps**, integer greater than ten\n",
        "steps = 20000 #@param {type:\"slider\", min:10, max:30000, step:5} \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "first_neural_net = run_better_neural_net_model(20000, #steps\n",
        "                                               selected_target, #features\n",
        "                                               selected_features, #targets\n",
        "                                               model_layers, #layers\n",
        "                                               percent_val #percent validation data, expressed as a decimal\n",
        "                                              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBioxBsnYET3",
        "colab_type": "text"
      },
      "source": [
        "#What Next?\n",
        "You've done it! You completed this course. If you want to learn more [here](https://colab.research.google.com/drive/1ZsHf655LcMHFCbgkMPEivbLP6Ja5UeKg) is a lesson on image classification."
      ]
    }
  ]
}